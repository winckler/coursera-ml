---
title: "Practical Machine Learning Report"
author: "Gabriel A. von Winckler"
date: "December 18, 2015"
output: 
  html_document: 
    keep_md: yes
    toc: yes
---

# Summary

This is a report on the course project from the Practical Machine Learning course from Johns Hopkins University Data Science specialization on Coursera. This exercise uses the "Weight Lifting Exercise Dataset" from PUC-Rio. The goal is to create and train a machine learn model and evaluate it's performance with a test sub-sample.

# Setup

This work uses the _caret_ package from R. The package _doMC_ allow parallel computation using multiple threads and was also used to allow speed-up the model training using all the cores in the machine (4 cores).

A seed was fixed for reproducibility purpose.

```{r}
library(caret)

library(doMC)
registerDoMC(cores = 4)

set.seed(999)
```

# Model creation

## Cleaning

The data was loaded from the CSV file. Than it was splitted in training and test subsets. The training subset has 75% of the original samples.

```{r}
all <- read.csv("pml-training.csv")
inTrain <- createDataPartition(y=all$classe, p=0.75, list=F)
training <- all[inTrain,]
test <- all[-inTrain,]
```

Than the dataset (training subset only) was cleaned to remove:

* obvious unclassifiable columns (X, user_name, *_timestamp, *_window)
* near zero covariates
* column with almost all values _NA_

```{r}
# remove X, user_name, *_timestamp, *_window
training <- training[,8:160]

# remove near zero covariates
nzv <- nearZeroVar(training, saveMetrics=TRUE)
training <- training[,!nzv[,4]]

# remove columns with NA
training <- training[, colSums(is.na(training)) == 0]
```

## Training

Some different models were tested, such as _Random Forests_, _Classification and regression trees_ and _Classification and regression trees_. Due to the accuracy and processing time, the _Random Forests_ was selected for this model.

Also, to speed-up the training, the training control was tweaked, using _8-fold cross-validation_. (8 was chosen as a multiple of the number of cores for better performance)

```{r cache=TRUE}
model <- train(classe ~ ., data=training, method="rf", 
               trControl=trainControl(method="cv", number=8))
```

# Performance

## In-sample

The in-sample performance was evaluated using the _confusionMatrix_ function.

```{r}
pred <- predict(model, training)
cm <- confusionMatrix(pred, training$classe)
print(cm)
```

As you can see, the performance is excellent.

## Out-of-sample

Regarding the out-of-sample performance, the same approach was used:

```{r}
pred_test <- predict(model, test)
cm_test <- confusionMatrix(pred_test, test$classe)
print(cm_test)
```

The result is impressive, with an accuracy of `r cm_test$overall["Accuracy"]` yielding an confidence interval (CI) of (`r cm_test$overall["AccuracyLower"]`,`r cm_test$overall["AccuracyUpper"]`)


# References
```
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
```